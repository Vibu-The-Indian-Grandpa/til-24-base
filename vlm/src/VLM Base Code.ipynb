{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95f51094-f151-4c90-89c2-981e70ad34e2",
   "metadata": {},
   "source": [
    "### VLM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7925de2-b09e-4089-bb20-84f43764d39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:datasets:PyTorch version 2.3.0 available.\n",
      "INFO:datasets:TensorFlow version 2.10.0 available.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "cppe5 = load_dataset(\"cppe-5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e240090-4dda-46e3-b5fa-4de2f6df6308",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoImageProcessor\n",
    "\n",
    "checkpoint = \"facebook/detr-resnet-50\"\n",
    "image_processor = AutoImageProcessor.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251405d7-a6fe-47a0-bc77-dcdcd1e141cf",
   "metadata": {},
   "source": [
    "## Preprocessing \n",
    "\n",
    "1) resizing the image\n",
    "2) Darken or Lighten the image(Based on probability)\n",
    "3) Anything Else to Add more noises to the the data\n",
    "\n",
    "The field are all copy pasted as of now, chage it according to what is needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "512b89e6-a87b-4134-916e-9e33eb4096ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "transform = albumentations.Compose(\n",
    "    [\n",
    "        albumentations.Resize(480, 480),\n",
    "        albumentations.HorizontalFlip(p=0.5),\n",
    "        albumentations.Blur(blur_limit=7, always_apply=True, p=1),\n",
    "        albumentations.RandomBrightnessContrast(p=1),\n",
    "    ],\n",
    "    bbox_params=albumentations.BboxParams(format=\"coco\", label_fields=[\"category\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48078d1e-d049-4724-a32f-ee6a92381a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatted_anns(image_id, category, area, bbox):\n",
    "    annotations = []\n",
    "    for i in range(0, len(category)):\n",
    "        new_ann = {\n",
    "            \"image_id\": image_id,\n",
    "            \"category_id\": category[i],\n",
    "            \"isCrowd\": 0,\n",
    "            \"area\": area[i],\n",
    "            \"bbox\": list(bbox[i]),\n",
    "        }\n",
    "        annotations.append(new_ann)\n",
    "\n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bd5a547-d828-4312-9dc4-18be37481c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming a batch\n",
    "def transform_aug_ann(examples):\n",
    "    \n",
    "    image_ids = examples[\"image_id\"]\n",
    "    images, bboxes, area, categories = [], [], [], []\n",
    "    for image, objects in zip(examples[\"image\"], examples[\"objects\"]):\n",
    "        image = np.array(image.convert(\"RGB\"))[:, :, ::-1]\n",
    "        out = transform(image=image, bboxes=objects[\"bbox\"], category=objects[\"category\"])\n",
    "\n",
    "        area.append(objects[\"area\"])\n",
    "        images.append(out[\"image\"])\n",
    "        bboxes.append(out[\"bboxes\"])\n",
    "        categories.append(out[\"category\"])\n",
    "\n",
    "    targets = [\n",
    "        {\"image_id\": id_, \"annotations\": formatted_anns(id_, cat_, ar_, box_)}\n",
    "        for id_, cat_, ar_, box_ in zip(image_ids, categories, area, bboxes)\n",
    "    ]\n",
    "\n",
    "    return image_processor(images=images, annotations=targets, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0cbfe73-4c4a-410c-9bcd-08d59cfcbe00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cppe5[\"train\"] = cppe5[\"train\"].with_transform(transform_aug_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5355a3c-52af-416d-a441-c8d16af8a4be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
